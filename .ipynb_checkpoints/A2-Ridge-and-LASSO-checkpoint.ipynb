{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 2 - Ridge and LASSO Regression\n",
    "\n",
    "### Due: Tuesday, July 9th, 11:59 pm on Gradescope.\n",
    "\n",
    "In this assignment we'll look at the affect of using regularization on linear regression models that we train. You will write code to train models that use different regularizers and different penalties and to analyze how this affects the model.\n",
    "\n",
    "\n",
    "Fill in the cells provided marked `TODO` with code to answer the questions. **Unless otherwise noted, every answer you submit should have code that clearly shows the answer in the output.** Answers submitted that do not have associated code that shows the answer may not be accepted for credit. \n",
    "\n",
    "It is generally a good idea to restart the kernel and run all cells (especially before turning it in) to make sure your code runs correctly. Answer the questions on Gradescope and make sure to download this file once you've finished the assignment and upload it to Canvas as well.\n",
    "\n",
    "> Copyright ©2019 Emily Fox and Hunter Schafer.  All rights reserved.  Permission is hereby granted to students registered for University of Washington CSE/STAT 416 for use solely during Summer Quarter 2019 for purposes of the course.  No other use, copying, distribution, or modification is permitted without prior written consent. Copyrights for third-party components of this work must be honored.  Instructors interested in reusing these course materials should contact the author.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conventionally people rename these common imports for brevity\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Magic command to make the plots appear in-line (it's actually called a \"magic command\")\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this assignment, we will only be using a very small subset of the data to do our analysis. This is not something you would usually do in practice, but is something we do for this assignment to simplify this complexity of this dataset. The data is pretty noisy and to get meaningful results to demonstrate the theoretical behavior, you would need to use a much more complicated set of features that would be a bit more tedious to work with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of points: 216\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>price</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>sqft_living</th>\n",
       "      <th>sqft_lot</th>\n",
       "      <th>floors</th>\n",
       "      <th>waterfront</th>\n",
       "      <th>view</th>\n",
       "      <th>...</th>\n",
       "      <th>grade</th>\n",
       "      <th>sqft_above</th>\n",
       "      <th>sqft_basement</th>\n",
       "      <th>yr_built</th>\n",
       "      <th>yr_renovated</th>\n",
       "      <th>zipcode</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>sqft_living15</th>\n",
       "      <th>sqft_lot15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17384</th>\n",
       "      <td>1453602313</td>\n",
       "      <td>20141029T000000</td>\n",
       "      <td>297000</td>\n",
       "      <td>2</td>\n",
       "      <td>1.50</td>\n",
       "      <td>1430</td>\n",
       "      <td>1650</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>1430</td>\n",
       "      <td>0</td>\n",
       "      <td>1999</td>\n",
       "      <td>0</td>\n",
       "      <td>98125</td>\n",
       "      <td>47.7222</td>\n",
       "      <td>-122.290</td>\n",
       "      <td>1430</td>\n",
       "      <td>1650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>722</th>\n",
       "      <td>2225059214</td>\n",
       "      <td>20140808T000000</td>\n",
       "      <td>1578000</td>\n",
       "      <td>4</td>\n",
       "      <td>3.25</td>\n",
       "      <td>4670</td>\n",
       "      <td>51836</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>12</td>\n",
       "      <td>4670</td>\n",
       "      <td>0</td>\n",
       "      <td>1988</td>\n",
       "      <td>0</td>\n",
       "      <td>98005</td>\n",
       "      <td>47.6350</td>\n",
       "      <td>-122.164</td>\n",
       "      <td>4230</td>\n",
       "      <td>41075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2680</th>\n",
       "      <td>2768000270</td>\n",
       "      <td>20140625T000000</td>\n",
       "      <td>562100</td>\n",
       "      <td>2</td>\n",
       "      <td>0.75</td>\n",
       "      <td>1440</td>\n",
       "      <td>3700</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>1200</td>\n",
       "      <td>240</td>\n",
       "      <td>1914</td>\n",
       "      <td>0</td>\n",
       "      <td>98107</td>\n",
       "      <td>47.6707</td>\n",
       "      <td>-122.364</td>\n",
       "      <td>1440</td>\n",
       "      <td>4300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18754</th>\n",
       "      <td>6819100040</td>\n",
       "      <td>20140624T000000</td>\n",
       "      <td>631500</td>\n",
       "      <td>2</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1130</td>\n",
       "      <td>2640</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>1130</td>\n",
       "      <td>0</td>\n",
       "      <td>1927</td>\n",
       "      <td>0</td>\n",
       "      <td>98109</td>\n",
       "      <td>47.6438</td>\n",
       "      <td>-122.357</td>\n",
       "      <td>1680</td>\n",
       "      <td>3200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14554</th>\n",
       "      <td>4027700666</td>\n",
       "      <td>20150426T000000</td>\n",
       "      <td>780000</td>\n",
       "      <td>4</td>\n",
       "      <td>2.50</td>\n",
       "      <td>3180</td>\n",
       "      <td>9603</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>9</td>\n",
       "      <td>3180</td>\n",
       "      <td>0</td>\n",
       "      <td>2002</td>\n",
       "      <td>0</td>\n",
       "      <td>98155</td>\n",
       "      <td>47.7717</td>\n",
       "      <td>-122.277</td>\n",
       "      <td>2440</td>\n",
       "      <td>15261</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               id             date    price  bedrooms  bathrooms  sqft_living  \\\n",
       "17384  1453602313  20141029T000000   297000         2       1.50         1430   \n",
       "722    2225059214  20140808T000000  1578000         4       3.25         4670   \n",
       "2680   2768000270  20140625T000000   562100         2       0.75         1440   \n",
       "18754  6819100040  20140624T000000   631500         2       1.00         1130   \n",
       "14554  4027700666  20150426T000000   780000         4       2.50         3180   \n",
       "\n",
       "       sqft_lot  floors  waterfront  view     ...      grade  sqft_above  \\\n",
       "17384      1650     3.0           0     0     ...          7        1430   \n",
       "722       51836     2.0           0     0     ...         12        4670   \n",
       "2680       3700     1.0           0     0     ...          7        1200   \n",
       "18754      2640     1.0           0     0     ...          8        1130   \n",
       "14554      9603     2.0           0     2     ...          9        3180   \n",
       "\n",
       "       sqft_basement  yr_built  yr_renovated  zipcode      lat     long  \\\n",
       "17384              0      1999             0    98125  47.7222 -122.290   \n",
       "722                0      1988             0    98005  47.6350 -122.164   \n",
       "2680             240      1914             0    98107  47.6707 -122.364   \n",
       "18754              0      1927             0    98109  47.6438 -122.357   \n",
       "14554              0      2002             0    98155  47.7717 -122.277   \n",
       "\n",
       "       sqft_living15  sqft_lot15  \n",
       "17384           1430        1650  \n",
       "722             4230       41075  \n",
       "2680            1440        4300  \n",
       "18754           1680        3200  \n",
       "14554           2440       15261  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sales = pd.read_csv('home_data.csv') \n",
    "\n",
    "# Selects 1% of the data\n",
    "sales = sales.sample(frac=0.01, random_state=0) \n",
    "\n",
    "print(f'Number of points: {len(sales)}')\n",
    "sales.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we do a bit of feature engineering by creating features that represent the squares of each feature and the square root of each feature. One benefit of using regularization is you can include more features than necessary and you don't have to be as worried about overfitting since the model is regularized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>price</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>sqft_living</th>\n",
       "      <th>sqft_lot</th>\n",
       "      <th>floors</th>\n",
       "      <th>waterfront</th>\n",
       "      <th>view</th>\n",
       "      <th>...</th>\n",
       "      <th>grade_square</th>\n",
       "      <th>grade_sqrt</th>\n",
       "      <th>sqft_above_square</th>\n",
       "      <th>sqft_above_sqrt</th>\n",
       "      <th>sqft_basement_square</th>\n",
       "      <th>sqft_basement_sqrt</th>\n",
       "      <th>yr_built_square</th>\n",
       "      <th>yr_built_sqrt</th>\n",
       "      <th>yr_renovated_square</th>\n",
       "      <th>yr_renovated_sqrt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17384</th>\n",
       "      <td>1453602313</td>\n",
       "      <td>20141029T000000</td>\n",
       "      <td>297000</td>\n",
       "      <td>2</td>\n",
       "      <td>1.50</td>\n",
       "      <td>1430</td>\n",
       "      <td>1650</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>49</td>\n",
       "      <td>2.645751</td>\n",
       "      <td>2044900</td>\n",
       "      <td>37.815341</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3996001</td>\n",
       "      <td>44.710178</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>722</th>\n",
       "      <td>2225059214</td>\n",
       "      <td>20140808T000000</td>\n",
       "      <td>1578000</td>\n",
       "      <td>4</td>\n",
       "      <td>3.25</td>\n",
       "      <td>4670</td>\n",
       "      <td>51836</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>144</td>\n",
       "      <td>3.464102</td>\n",
       "      <td>21808900</td>\n",
       "      <td>68.337398</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3952144</td>\n",
       "      <td>44.586994</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2680</th>\n",
       "      <td>2768000270</td>\n",
       "      <td>20140625T000000</td>\n",
       "      <td>562100</td>\n",
       "      <td>2</td>\n",
       "      <td>0.75</td>\n",
       "      <td>1440</td>\n",
       "      <td>3700</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>49</td>\n",
       "      <td>2.645751</td>\n",
       "      <td>1440000</td>\n",
       "      <td>34.641016</td>\n",
       "      <td>57600</td>\n",
       "      <td>15.491933</td>\n",
       "      <td>3663396</td>\n",
       "      <td>43.749286</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18754</th>\n",
       "      <td>6819100040</td>\n",
       "      <td>20140624T000000</td>\n",
       "      <td>631500</td>\n",
       "      <td>2</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1130</td>\n",
       "      <td>2640</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>64</td>\n",
       "      <td>2.828427</td>\n",
       "      <td>1276900</td>\n",
       "      <td>33.615473</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3713329</td>\n",
       "      <td>43.897608</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14554</th>\n",
       "      <td>4027700666</td>\n",
       "      <td>20150426T000000</td>\n",
       "      <td>780000</td>\n",
       "      <td>4</td>\n",
       "      <td>2.50</td>\n",
       "      <td>3180</td>\n",
       "      <td>9603</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>81</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>10112400</td>\n",
       "      <td>56.391489</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4008004</td>\n",
       "      <td>44.743715</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 47 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               id             date    price  bedrooms  bathrooms  sqft_living  \\\n",
       "17384  1453602313  20141029T000000   297000         2       1.50         1430   \n",
       "722    2225059214  20140808T000000  1578000         4       3.25         4670   \n",
       "2680   2768000270  20140625T000000   562100         2       0.75         1440   \n",
       "18754  6819100040  20140624T000000   631500         2       1.00         1130   \n",
       "14554  4027700666  20150426T000000   780000         4       2.50         3180   \n",
       "\n",
       "       sqft_lot  floors  waterfront  view        ...          grade_square  \\\n",
       "17384      1650     3.0           0     0        ...                    49   \n",
       "722       51836     2.0           0     0        ...                   144   \n",
       "2680       3700     1.0           0     0        ...                    49   \n",
       "18754      2640     1.0           0     0        ...                    64   \n",
       "14554      9603     2.0           0     2        ...                    81   \n",
       "\n",
       "       grade_sqrt  sqft_above_square  sqft_above_sqrt  sqft_basement_square  \\\n",
       "17384    2.645751            2044900        37.815341                     0   \n",
       "722      3.464102           21808900        68.337398                     0   \n",
       "2680     2.645751            1440000        34.641016                 57600   \n",
       "18754    2.828427            1276900        33.615473                     0   \n",
       "14554    3.000000           10112400        56.391489                     0   \n",
       "\n",
       "       sqft_basement_sqrt  yr_built_square  yr_built_sqrt  \\\n",
       "17384            0.000000          3996001      44.710178   \n",
       "722              0.000000          3952144      44.586994   \n",
       "2680            15.491933          3663396      43.749286   \n",
       "18754            0.000000          3713329      43.897608   \n",
       "14554            0.000000          4008004      44.743715   \n",
       "\n",
       "       yr_renovated_square  yr_renovated_sqrt  \n",
       "17384                    0                0.0  \n",
       "722                      0                0.0  \n",
       "2680                     0                0.0  \n",
       "18754                    0                0.0  \n",
       "14554                    0                0.0  \n",
       "\n",
       "[5 rows x 47 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from math import sqrt\n",
    "\n",
    "# All of the features of interest\n",
    "features = [\n",
    "    'bedrooms', \n",
    "    'bathrooms',\n",
    "    'sqft_living', \n",
    "    'sqft_lot', \n",
    "    'floors', \n",
    "    'waterfront', \n",
    "    'view', \n",
    "    'condition', \n",
    "    'grade',\n",
    "    'sqft_above',\n",
    "    'sqft_basement',\n",
    "    'yr_built', \n",
    "    'yr_renovated'\n",
    "]\n",
    "\n",
    "# Compute the square and sqrt of each feature\n",
    "all_features = []\n",
    "for feat in features:\n",
    "    square_feat = feat + '_square'\n",
    "    sqrt_feat = feat + '_sqrt'\n",
    "    \n",
    "    sales[square_feat] = sales[feat] ** 2\n",
    "    sales[sqrt_feat] = sales[feat].apply(sqrt)\n",
    "    \n",
    "    all_features.extend([feat, square_feat, sqrt_feat])\n",
    "    \n",
    "sales.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first need to do a little bit more pre-processing to prepare the data for model training. Models like Ridge and LASSO assume the input features are standardized (mean 0, std. dev. 1) and the target values are centered (mean 0). If we do not do this, we might get some unpredictable results since we violate the assumption of the models!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>price</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>sqft_living</th>\n",
       "      <th>sqft_lot</th>\n",
       "      <th>floors</th>\n",
       "      <th>waterfront</th>\n",
       "      <th>view</th>\n",
       "      <th>...</th>\n",
       "      <th>grade_square</th>\n",
       "      <th>grade_sqrt</th>\n",
       "      <th>sqft_above_square</th>\n",
       "      <th>sqft_above_sqrt</th>\n",
       "      <th>sqft_basement_square</th>\n",
       "      <th>sqft_basement_sqrt</th>\n",
       "      <th>yr_built_square</th>\n",
       "      <th>yr_built_sqrt</th>\n",
       "      <th>yr_renovated_square</th>\n",
       "      <th>yr_renovated_sqrt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17384</th>\n",
       "      <td>1453602313</td>\n",
       "      <td>20141029T000000</td>\n",
       "      <td>-2.494620e+05</td>\n",
       "      <td>-1.732713</td>\n",
       "      <td>-0.850304</td>\n",
       "      <td>-0.750014</td>\n",
       "      <td>-0.388060</td>\n",
       "      <td>2.744430</td>\n",
       "      <td>-0.118403</td>\n",
       "      <td>-0.284816</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.596346</td>\n",
       "      <td>-0.578973</td>\n",
       "      <td>-0.499020</td>\n",
       "      <td>-0.459475</td>\n",
       "      <td>-0.462336</td>\n",
       "      <td>-0.687521</td>\n",
       "      <td>0.887345</td>\n",
       "      <td>0.884234</td>\n",
       "      <td>-0.219776</td>\n",
       "      <td>-0.219813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>722</th>\n",
       "      <td>2225059214</td>\n",
       "      <td>20140808T000000</td>\n",
       "      <td>1.031538e+06</td>\n",
       "      <td>0.705502</td>\n",
       "      <td>1.453745</td>\n",
       "      <td>2.818818</td>\n",
       "      <td>1.124834</td>\n",
       "      <td>0.850510</td>\n",
       "      <td>-0.118403</td>\n",
       "      <td>-0.284816</td>\n",
       "      <td>...</td>\n",
       "      <td>4.108393</td>\n",
       "      <td>3.239989</td>\n",
       "      <td>3.985305</td>\n",
       "      <td>2.771992</td>\n",
       "      <td>-0.462336</td>\n",
       "      <td>-0.687521</td>\n",
       "      <td>0.514800</td>\n",
       "      <td>0.519862</td>\n",
       "      <td>-0.219776</td>\n",
       "      <td>-0.219813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2680</th>\n",
       "      <td>2768000270</td>\n",
       "      <td>20140625T000000</td>\n",
       "      <td>1.563804e+04</td>\n",
       "      <td>-1.732713</td>\n",
       "      <td>-1.837753</td>\n",
       "      <td>-0.738999</td>\n",
       "      <td>-0.326261</td>\n",
       "      <td>-1.043409</td>\n",
       "      <td>-0.118403</td>\n",
       "      <td>-0.284816</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.596346</td>\n",
       "      <td>-0.578973</td>\n",
       "      <td>-0.636268</td>\n",
       "      <td>-0.795551</td>\n",
       "      <td>-0.343052</td>\n",
       "      <td>0.511572</td>\n",
       "      <td>-1.937984</td>\n",
       "      <td>-1.958030</td>\n",
       "      <td>-0.219776</td>\n",
       "      <td>-0.219813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18754</th>\n",
       "      <td>6819100040</td>\n",
       "      <td>20140624T000000</td>\n",
       "      <td>8.503804e+04</td>\n",
       "      <td>-1.732713</td>\n",
       "      <td>-1.508604</td>\n",
       "      <td>-1.080461</td>\n",
       "      <td>-0.358216</td>\n",
       "      <td>-1.043409</td>\n",
       "      <td>-0.118403</td>\n",
       "      <td>-0.284816</td>\n",
       "      <td>...</td>\n",
       "      <td>0.146507</td>\n",
       "      <td>0.273513</td>\n",
       "      <td>-0.673274</td>\n",
       "      <td>-0.904128</td>\n",
       "      <td>-0.462336</td>\n",
       "      <td>-0.687521</td>\n",
       "      <td>-1.513825</td>\n",
       "      <td>-1.519301</td>\n",
       "      <td>-0.219776</td>\n",
       "      <td>-0.219813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14554</th>\n",
       "      <td>4027700666</td>\n",
       "      <td>20150426T000000</td>\n",
       "      <td>2.335380e+05</td>\n",
       "      <td>0.705502</td>\n",
       "      <td>0.466296</td>\n",
       "      <td>1.177596</td>\n",
       "      <td>-0.148311</td>\n",
       "      <td>0.850510</td>\n",
       "      <td>-0.118403</td>\n",
       "      <td>2.389978</td>\n",
       "      <td>...</td>\n",
       "      <td>0.988408</td>\n",
       "      <td>1.074185</td>\n",
       "      <td>1.331444</td>\n",
       "      <td>1.507241</td>\n",
       "      <td>-0.462336</td>\n",
       "      <td>-0.687521</td>\n",
       "      <td>0.989306</td>\n",
       "      <td>0.983434</td>\n",
       "      <td>-0.219776</td>\n",
       "      <td>-0.219813</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 47 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               id             date         price  bedrooms  bathrooms  \\\n",
       "17384  1453602313  20141029T000000 -2.494620e+05 -1.732713  -0.850304   \n",
       "722    2225059214  20140808T000000  1.031538e+06  0.705502   1.453745   \n",
       "2680   2768000270  20140625T000000  1.563804e+04 -1.732713  -1.837753   \n",
       "18754  6819100040  20140624T000000  8.503804e+04 -1.732713  -1.508604   \n",
       "14554  4027700666  20150426T000000  2.335380e+05  0.705502   0.466296   \n",
       "\n",
       "       sqft_living  sqft_lot    floors  waterfront      view  \\\n",
       "17384    -0.750014 -0.388060  2.744430   -0.118403 -0.284816   \n",
       "722       2.818818  1.124834  0.850510   -0.118403 -0.284816   \n",
       "2680     -0.738999 -0.326261 -1.043409   -0.118403 -0.284816   \n",
       "18754    -1.080461 -0.358216 -1.043409   -0.118403 -0.284816   \n",
       "14554     1.177596 -0.148311  0.850510   -0.118403  2.389978   \n",
       "\n",
       "             ...          grade_square  grade_sqrt  sqft_above_square  \\\n",
       "17384        ...             -0.596346   -0.578973          -0.499020   \n",
       "722          ...              4.108393    3.239989           3.985305   \n",
       "2680         ...             -0.596346   -0.578973          -0.636268   \n",
       "18754        ...              0.146507    0.273513          -0.673274   \n",
       "14554        ...              0.988408    1.074185           1.331444   \n",
       "\n",
       "       sqft_above_sqrt  sqft_basement_square  sqft_basement_sqrt  \\\n",
       "17384        -0.459475             -0.462336           -0.687521   \n",
       "722           2.771992             -0.462336           -0.687521   \n",
       "2680         -0.795551             -0.343052            0.511572   \n",
       "18754        -0.904128             -0.462336           -0.687521   \n",
       "14554         1.507241             -0.462336           -0.687521   \n",
       "\n",
       "       yr_built_square  yr_built_sqrt  yr_renovated_square  yr_renovated_sqrt  \n",
       "17384         0.887345       0.884234            -0.219776          -0.219813  \n",
       "722           0.514800       0.519862            -0.219776          -0.219813  \n",
       "2680         -1.937984      -1.958030            -0.219776          -0.219813  \n",
       "18754        -1.513825      -1.519301            -0.219776          -0.219813  \n",
       "14554         0.989306       0.983434            -0.219776          -0.219813  \n",
       "\n",
       "[5 rows x 47 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def standardize(v):\n",
    "    \"\"\"\n",
    "    Takes a single column of a DataFrame and returns a new column \n",
    "    with the data standardized (mean 0, std deviation 1)\n",
    "    \"\"\"\n",
    "    std = v.std()\n",
    "    if std == 0:\n",
    "        return np.zeros(len(v))\n",
    "    else:\n",
    "        return (v - v.mean()) / std\n",
    "\n",
    "# Standardize each of the features\n",
    "for feature in all_features:\n",
    "    sales[feature] = standardize(sales[feature])\n",
    "    \n",
    "# Make the price have mean 0 \n",
    "mean_price = sales['price'].mean() \n",
    "sales['price'] -= mean_price\n",
    "\n",
    "# Preview\n",
    "sales.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will split the data set into training, validation, and test sets. To do this, we will use [train_test_split](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html) function to split up the dataset. For this assignment we will use 70% of the data to train, 10% for validation, and 20% to test. \n",
    "\n",
    "We have written most of the splitting for you, but we need you to figure out what the sizes should be in this case based off the numbers above. Remember, we use `random_state=6` to make sure the results are deterministic for our assignment. Don't modify any code in this section besides changing the `<NUM>`s to the correct values.\n",
    "\n",
    "*Hint: You should print out the length of the datasets to make sure you got it right!*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total length of dataset: 216\n",
      "Number of train & validation: 172\n",
      "Number of test: 44\n",
      "Number of train: 150\n",
      "Number of validation: 22\n"
     ]
    }
   ],
   "source": [
    "# TODO Fill in the numbers to make datasets of the right size.\n",
    "from sklearn.model_selection import train_test_split\n",
    "#Use 70% of data to train\n",
    "#Use 10% for validation\n",
    "#Use 20% to test\n",
    "#Expect 22 validation\n",
    "\n",
    "print(f'Total length of dataset: {len(sales)}')\n",
    "train_and_validation, test = train_test_split(sales, test_size=.20, random_state=6)\n",
    "train, validation = train_test_split(train_and_validation, test_size=.125, random_state=6)\n",
    "print(f'Number of train & validation: {len(train_and_validation)}')\n",
    "print(f'Number of test: {len(test)}')\n",
    "print(f'Number of train: {len(train)}')\n",
    "print(f'Number of validation: {len(validation)}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q1) Linear Regression\n",
    "As a baseline, we will first, train a regular `LinearRegression` model on the data using the features in `all_features` and report its **test RMSE** on Gradescope. Write the code in the cell below to calculate the answer. \n",
    "\n",
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Gradescope:</b> Type in the test error for the <code>LinearRegression</code> model. You should round the RMSE to the nearest integer. \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "384955.7529924656\n"
     ]
    }
   ],
   "source": [
    "# TODO Train a linear regression model\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import math\n",
    "\n",
    "X = train[all_features]\n",
    "Y = train['price']\n",
    "basicLinearRegression = LinearRegression().fit(X, Y)\n",
    "basicLinearRegressionTestError = mean_squared_error(test['price'], basicLinearRegression.predict(test[all_features]))\n",
    "print(math.sqrt(basicLinearRegressionTestError))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- \n",
    "## Ridge Regression\n",
    "At this point, you might be looking forward at the homework and seeing how long it is! We want to provide a lot of instruction so you aren't left completely in the dark on what to do, but we are also trying to avoid just giving you a bunch of starter code and just having you fill in the blanks. This section is very long because it tries to give really detailed instructions on what to compute. The next section on LASSO has almost exactly the same steps so it will be a lot easier doing that part of the assignment!\n",
    "\n",
    "In this section, we will do some **hyper-parameter tuning** to find the optimal setting of the regularization constant $\\lambda$ for Ridge Regression. Remember that $\\lambda$ is the coefficient that controls how much the model is penalized for having large weights in the optimization function.\n",
    "\n",
    "$$\\hat{w}_{ridge} = \\min_w RSS(w) + \\lambda \\left\\lVert w \\right\\rVert_2^2$$\n",
    "\n",
    "where $\\left\\lVert w \\right\\rVert_2^2 = \\sum_{j=0}^D w_j^2$ is the L2 norm of the parameters. By default, `sklearn`'s `Ridge` class does not regularize the intercept.\n",
    "\n",
    "For this part of the assignment, you will be writing code to find the optimal setting of the penalty $\\lambda$. Below, we describe what steps you will want to have in your code to compute these values:\n",
    "\n",
    "*Implementation Details*\n",
    "* Use the following choices of L2 penalty: $[10^{-5}, 10^{-4}, ..., 10^4, 10^5]$. In Python, you can create a list of these numbers using `np.logspace(-5, 5, 11)`. \n",
    "* Use the [Ridge](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Ridge.html#sklearn.linear_model.Ridge) class from sklearn to train a Ridge Regression model on the **training** data. The **only** parameters you need to pass when constructing the Ridge model are `alpha`, which lets you specify what you want the L2 penalty to be, and `random_state=0` to avoid randomness.\n",
    "* Evaluate both the training error and the validation error for the model by reporting the RMSE of each dataset.\n",
    "* Put all of your results in a pandas `DataFrame` named `ridge_data` so you can analyze them later. The `ridge_data` should have a row for each L2 penalty you tried and should have the following columns:\n",
    "  * `l2_penalty`: The L2 penalty for that row\n",
    "  * `model`: The actual `Ridge` model object that was trained with that L2 penalty\n",
    "  * `train_rmse`: The training RMSE for that model\n",
    "  * `validation_rmse`: The validation RMSE for that model\n",
    "* To build up this `DataFrame`, we recommend first building up a list of dictionary objects and then converting that to a `DataFrame`. For example, the following code would produce the following `pandas.DataFrame`.\n",
    "```python\n",
    "data = []\n",
    "for i in range(3):\n",
    "    data.append({\n",
    "        'col_a': i,\n",
    "        'col_b': 2 * i\n",
    "    }\n",
    "data_frame = pd.DataFrame(data)\n",
    "```\n",
    "\n",
    "| col_a | col_b | \n",
    "|-------|-------|\n",
    "|   0   |   0   | \n",
    "|   1   |   2   | \n",
    "|   2   |   4   |\n",
    "\n",
    "*Hints: Here is a development strategy that you might find helpful*\n",
    "* You will need a loop to loop over the possible L2 penalties. Try writing a lot of the code without a loop first if you're stuck to help you figure out how the pieces go together. You can safely ignore building up the result `DataFrame` at first, just print all the information out to start! \n",
    "* If you are running into troubles writing your loop, try to print values out to investigate what's going wrong.\n",
    "* Remember to use RMSE for calculating the error!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      l2_penalty                                              model  \\\n",
      "0        0.00001  Ridge(alpha=1e-05, copy_X=True, fit_intercept=...   \n",
      "1        0.00010  Ridge(alpha=0.0001, copy_X=True, fit_intercept...   \n",
      "2        0.00100  Ridge(alpha=0.001, copy_X=True, fit_intercept=...   \n",
      "3        0.01000  Ridge(alpha=0.01, copy_X=True, fit_intercept=T...   \n",
      "4        0.10000  Ridge(alpha=0.1, copy_X=True, fit_intercept=Tr...   \n",
      "5        1.00000  Ridge(alpha=1.0, copy_X=True, fit_intercept=Tr...   \n",
      "6       10.00000  Ridge(alpha=10.0, copy_X=True, fit_intercept=T...   \n",
      "7      100.00000  Ridge(alpha=100.0, copy_X=True, fit_intercept=...   \n",
      "8     1000.00000  Ridge(alpha=1000.0, copy_X=True, fit_intercept...   \n",
      "9    10000.00000  Ridge(alpha=10000.0, copy_X=True, fit_intercep...   \n",
      "10  100000.00000  Ridge(alpha=100000.0, copy_X=True, fit_interce...   \n",
      "\n",
      "       train_rmse  validation_rmse  \n",
      "0   146189.482787    392113.886095  \n",
      "1   146212.364397    392713.488969  \n",
      "2   146628.698076    392554.480303  \n",
      "3   148062.619776    366381.072228  \n",
      "4   151809.710037    328278.686355  \n",
      "5   155087.247334    300414.694936  \n",
      "6   162399.127654    280715.046802  \n",
      "7   185469.414716    281466.220013  \n",
      "8   254855.366272    368360.424703  \n",
      "9   332731.490623    495479.423202  \n",
      "10  354251.269335    529405.452793  \n"
     ]
    }
   ],
   "source": [
    "# TODO Implement code to evaluate Ridge Regression with various L2 Penalties\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "L2penalties = np.logspace(-5,5,11)\n",
    "#Only need to use alpha and random_state = 0\n",
    "ridge_data = []\n",
    "for penalty in L2penalties:\n",
    "    RidgeRegression = Ridge(alpha = penalty, random_state = 0)\n",
    "    RidgeRegression.fit(X,Y)\n",
    "    #Find the training and validation error:\n",
    "    RidgeTrainError = math.sqrt(mean_squared_error(train['price'], RidgeRegression.predict(train[all_features])))\n",
    "    RidgeValidationError = math.sqrt(mean_squared_error(validation['price'], RidgeRegression.predict(validation[all_features])))\n",
    "    ridge_data.append({'l2_penalty': penalty, 'model': RidgeRegression, 'train_rmse': RidgeTrainError,\n",
    "      'validation_rmse': RidgeValidationError})\n",
    "\n",
    "ridge_data = pd.DataFrame(ridge_data)  \n",
    "print(ridge_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a sanity check, the cells below make sure you have a variable named `ridge_data` with the right number of rows and columns. If nothing is printed out, you pass this sanity check! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert type(ridge_data) == pd.DataFrame\n",
    "assert len(ridge_data) == 11\n",
    "\n",
    "for col in ['l2_penalty', 'model', 'train_rmse', 'validation_rmse']:\n",
    "    assert col in ridge_data.columns, f'Missing column {col}'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's investigate how the penalty affected the train and validation error by running the following plotting code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1d474d72160>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZsAAAEPCAYAAACUb2mtAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAIABJREFUeJzt3Xl8VNX5+PHPQ9j3RVRkSbDFBRAQUoTaKmqVRStqEaEgoCiKtRa1rtgK+qWKUqVYwR9YATUVUaqiqJQq1qUqBtkESokKGtkCsqhBEHh+f5wTmITJyty5M5Pn/Xrd19w5c5fnJjBPzj3nniOqijHGGBOkKmEHYIwxJvVZsjHGGBM4SzbGGGMCZ8nGGGNM4CzZGGOMCZwlG2OMMYGzZGOMMSZwlmyMMcYEzpKNMcaYwFmyMcYYE7iqYQeQKI466ijNyMgIOwxjjEkqixcv3qqqTUvbzpKNl5GRQXZ2dthhGGNMUhGR9WXZzm6jGWOMCZwlG2OMMYGzZGOMMSZw1mZTgh9++IHc3Fy+//77sENJGTVr1qRFixZUq1Yt7FCMMXFkyaYEubm51KtXj4yMDEQk7HCSnqqybds2cnNzad26ddjhGGPiyG6jleD777+nSZMmlmhiRERo0qSJ1RSNSRBZWZCRAVWquNesrODOZTWbUliiiS37eRqTGLKyYMQIyM9379evd+8BBg2K/fmsZpPAevTowfz58wuVTZw4keuuu67YferWrQvAhg0b6NevX7HHLe2ZookTJ5Jf8K8Q6NOnDzt27Chr6MaYBHfLLYcSTYH8fBg9OpjzWbKJoVhXSQcOHMisWbMKlc2aNYuBAweWuu9xxx3H888/X+FzF002r776Kg0bNqzw8YwxiSEvD0aOhI0bo3/+xRfBnNeSTYwUVEnXrwfVQ1XSI0k4/fr145VXXmHPnj0ArFu3jg0bNtCpUyfOOeccOnfuzCmnnMJLL7102L7r1q2jffv2AOzevZsBAwbQoUMHLrvsMnbv3n1wu5EjR5KZmUm7du24++67AZg0aRIbNmzgrLPO4qyzzgLcCAtbt24F4KGHHqJ9+/a0b9+eiRMnHjzfySefzNVXX027du0477zzCp3HGBOuH36AiROhTRuYNg3q1Yu+XatWwZzf2mzKaNQoWLq0+M8/+AB8TjgoPx+GD3e/2Gg6dXK//OI0adKErl278vrrr9O3b19mzZrFZZddRq1atXjhhReoX78+W7dupVu3blx44YXFtodMmTKF2rVrs3z5cpYvX07nzp0PfjZu3DgaN27M/v37Oeecc1i+fDk33HADDz30EAsXLuSoo44qdKzFixczffp0PvzwQ1SV0047jTPPPJNGjRqxdu1annnmGaZNm0b//v2ZM2cOgwcPLv4CjTFx8eqrcNNNsGYN9OwJDz0ES5YUbrMBqF0bxo0LJgar2cRI0URTWnlZRd5KK7iFpqrceeeddOjQgV/84hd89dVXbN68udhjvP322we/9Dt06ECHDh0OfjZ79mw6d+7MqaeeysqVK1m1alWJ8bz77rtcfPHF1KlTh7p163LJJZfwzjvvANC6dWs6deoEQJcuXVi3bt2RXLox5gitXg29e8P557s7Lq+8Aq+9Bm3buk4AU6dCejqIuNepU4PpHABWsymzkmog4Npo1kcZji49Hd56q+Lnveiii7jpppv4+OOP2b17N507d2bGjBnk5eWxePFiqlWrRkZGRqndiaPVej7//HMmTJjARx99RKNGjRg2bFipx1HVYj+rUaPGwfW0tDS7jWZMSLZvhzFj4NFHoW5dV5P5zW+gevXC2w0aFFxyKcpqNjEybpyrgkaKRZW0bt269OjRgyuvvPJgx4CdO3dy9NFHU61aNRYuXMj6aFkuwhlnnEGWbzz65JNPWL58OQC7du2iTp06NGjQgM2bN/Paa68d3KdevXp88803UY/14osvkp+fz3fffccLL7zAz3/+8yO7SGNMTOzbB5Mnu3aZv/4VrroK1q6FG288PNHEm9VsYqTgr4PRo11vjlatXKKJxV8NAwcO5JJLLjl4O23QoEH88pe/JDMzk06dOnHSSSeVuP/IkSO54oor6NChA506daJr164AdOzYkVNPPZV27dpx/PHHc/rppx/cZ8SIEfTu3ZtmzZqxcOHCg+WdO3dm2LBhB49x1VVXceqpp9otM2NC9q9/uaTyySdw1lnubkzEHfPQSUm3RSqTzMxMLfrsyerVqzn55JNDiih12c/VmNjJyYGbb4a5c6F1a5gwAS6+2LXDxIOILFbVzNK2s9toxhiThHbtgltvdY39b74J990Hq1bBJZfEL9GUh91GM8aYJLJ/P0yf7m7Z5+XBsGHuln2zZmFHVjJLNsYYkyTefts987dkCZx+OsybB5ml3sBKDIHeRhORdSKyQkSWiki2L2ssIgtEZK1/beTLRUQmiUiOiCwXkc4Rxxnqt18rIkMjyrv44+f4faWkcxhjTDJatw7694czz4StW+GZZ+Cdd5In0UB82mzOUtVOEQ1ItwNvqGob4A3/HqA30MYvI4Ap4BIHcDdwGtAVuDsieUzx2xbs16uUcxhjTNL49lu46y446ST3QObYsfDf/8KAAYnZLlOSMDoI9AVm+vWZwEUR5U+q8wHQUESaAT2BBar6tapuBxYAvfxn9VX1fXVd6p4scqxo5zDGmIR34AA89RSceKJrj/nVr9xQM3/84+HP8yWLoJONAv8UkcUi4mdK4BhV3QjgX4/25c2BLyP2zfVlJZXnRikv6RxJZdu2bXTq1IlOnTpx7LHH0rx584Pv9+7dW6ZjXHHFFaxZsybgSI0xFVV0tPixY6F7dxgyBI47Dt57z23TsmXYkR6ZoDsInK6qG0TkaGCBiPy3hG2jVQq1AuVl5hPgCIBWsRjqNCsrpk91NmnShKV+9M8xY8ZQt25dfv/73xfaRlVRVapUif53w/Tp0yt8fmNMsKJNYDZmDDRoADNmwOWXuySUCgK9DFXd4F+3AC/g2lw2+1tg+NctfvNcIDJ3twA2lFLeIko5JZyjaHxTVTVTVTObNm1a0ct0gphjoBg5OTm0b9+ea6+9ls6dO7Nx40ZGjBhxcKqAe+655+C2P/vZz1i6dCn79u2jYcOG3H777XTs2JHu3buzZUvUH4sxJk5Gjz58AjOA+vVh6NDUSTQQYLIRkToiUq9gHTgP+ASYCxT0KBsKFEzGMhcY4nuldQN2+ltg84HzRKSR7xhwHjDff/aNiHTzvdCGFDlWtHNU3KhR0KNH8cvw4dGnvRs+vPh9Ro2qcDirVq1i+PDhLFmyhObNm3P//feTnZ3NsmXLWLBgQdTRm3fu3MmZZ57JsmXL6N69O0888USFz2+MOXLFTVSWmxu9PJkFmTePAd4VkWXAImCeqr4O3A+cKyJrgXP9e4BXgc+AHGAacB2Aqn4N3At85Jd7fBnASOBxv8+nQMFIksWdIzhBzTFQjB/96Ef85Cc/Ofj+mWeeoXPnznTu3JnVq1dHTTa1atWid+/egE0BYEwiKO7ufVATmIUpsDYbVf0M6BilfBtwTpRyBX5TzLGeAA77M1xVs4H2ZT3HEQlrjoFi1KlT5+D62rVr+ctf/sKiRYto2LAhgwcPjjpVQPWIYV/T0tLYt29fzOMyxpTdvfe622WRQ1QGOYFZmFLojmDIgppjoAx27dpFvXr1qF+/Phs3bmT+/PmBn9MYc+SqVXOJpmnT+ExgFiYbriZWgpxjoBSdO3embdu2tG/f/rCpAowxiUkVxo93z9KsWpVanQGisSkGPJtiIH7s52oMLFgA550Hjz/u+hElK5tiwBhjEtj48e6hzcGDw44kPizZGGNMnC1eDG+84Z5+qFEj7Gjiw5KNMcbE2fjx7sHNESNK3zZVWLIphbVpxZb9PE1ll5MDc+bAyJFuWJrKwpJNCWrWrMm2bdvsCzJGVJVt27ZRs2bNsEMxJjQTJkDVqvC734UdSXxZ1+cStGjRgtzcXPLy8sIOJWXUrFmTFi1alL6hMSlo82Y3wObQoYk/jXOsWbIpQbVq1WjdunXYYRhjUsSkSbB3LxQZvL1SsNtoxhgTB998A5Mnw8UXwwknhB1N/FmyMcaYOJg6FXbsgNtuCzuScFiyMcaYgO3dCw8/7GYW6do17GjCYW02xhgTsKws+OorNzRNZWU1G2OMCdCBA/Dgg9CxI/TsGXY04bGajTHGBOiVV2D1ale7EQk7mvBYzcYYYwI0frybp6Z//7AjCVfgyUZE0kRkiYi84t/PEJHPRWSpXzr5chGRSSKSIyLLRaRzxDGGishavwyNKO8iIiv8PpNE3N8NItJYRBb47ReISKOgr9MYY4p69134z3/g5pvdqAGVWTxqNr8DVhcpu0VVO/llqS/rDbTxywhgCrjEAdwNnAZ0Be6OSB5T/LYF+/Xy5bcDb6hqG+AN/94YY+Jq/Hho0gSuvDLsSMIXaLIRkRbA+UBZ+mD0BZ5U5wOgoYg0A3oCC1T1a1XdDiwAevnP6qvq++oGL3sSuCjiWDP9+syIcmOMiYuVK117zW9/C3XqhB1N+IKu2UwEbgUOFCkf52+VPSwiBbM5NAe+jNgm15eVVJ4bpRzgGFXdCOBfj44WnIiMEJFsEcm28c+MMbH04INQuzZcf33YkSSGwJKNiFwAbFHVxUU+ugM4CfgJ0BgoeJ42Wj8NrUB5manqVFXNVNXMpk2blmdXY4wp1pdfut5nV13lbqOZYGs2pwMXisg6YBZwtog8raob/a2yPcB0XDsMuJpJy4j9WwAbSilvEaUcYLO/zYZ/3RLLCzPGmJI8/DCowo03hh1J4ggs2ajqHaraQlUzgAHAm6o6OCIJCK4t5RO/y1xgiO+V1g3Y6W+BzQfOE5FGvmPAecB8/9k3ItLNH2sI8FLEsQp6rQ2NKDfGmEB9/bUbB23AAMjICDuaxBFGZ7wsEWmKuw22FLjWl78K9AFygHzgCgBV/VpE7gU+8tvdo6pf+/WRwAygFvCaXwDuB2aLyHDgC+DSIC/IGGMKTJ4M330Ht94adiSJRWwWSiczM1Ozs7PDDsMYk8R273YPcGZmwquvhh1NfIjIYlXNLG07G0HAGGNiZMYMyMurvNMIlMSSjTHGxMC+fTBhApx2GpxxRtjRJJ5KPoCCMcbExpw58Nln7vmayjzgZnGsZmOMMUdI1Q1Nc8IJ0Ldv2NEkJqvZGGPMEfrXv2DJEpg2DdLSwo4mMVnNxhhjjtADD0CzZnD55WFHkrgs2RhjzBFYvNjVbEaNgho1St++srJkY4wxR+CBB6B+fbjmmrAjSWyWbIwxpoI+/RSefx6uvRYaNAg7msRmycYYYypowgQ3A+eoUWFHkvgs2RhjTAVs3gzTp8OQIa5zgCmZJRtjjKmARx6BvXvhllvCjiQ5WLIxxphy+uYbePRRuPhi9yCnKZ0lG2OMKadp02DHDptGoDws2RhjTDns3QsPPQRnnukG3TRlY8PVGGNMOfz97/DVV652Y8ou8JqNiKSJyBIRecW/by0iH4rIWhF5VkSq+/Ia/n2O/zwj4hh3+PI1ItIzoryXL8sRkdsjyqOewxhjjsSBA25U5w4doFevsKNJLvG4jfY7YHXE+/HAw6raBtgODPflw4Htqvpj4GG/HSLSFhgAtAN6AZN9AksDHgV6A22BgX7bks5hjDEVNm8erFrl2mpsGoHyCTTZiEgL4Hzgcf9egLOB5/0mM4GL/Hpf/x7/+Tl++77ALFXdo6qfAzlAV7/kqOpnqroXmAX0LeUcxhhTYePHu2mf+/cPO5LkE3TNZiJwK3DAv28C7FDVff59LtDcrzcHvgTwn+/02x8sL7JPceUlncMYYyrkvffcctNNUK1a2NEkn8CSjYhcAGxR1cWRxVE21VI+i1V5tBhHiEi2iGTn5eVF28QYYwBXq2nSBIbbTfkKCbJmczpwoYisw93iOhtX02koIgW94FoAG/x6LtASwH/eAPg6srzIPsWVby3hHIWo6lRVzVTVzKZNm5b7ArOyICMDqlRxr1lZ5T5EhYV17jCv2ZiwrFwJL78M118PdeqEHU2SUtXAF6AH8Ipffw4Y4NcfA67z678BHvPrA4DZfr0dsAyoAbQGPgPScN22P/Nl1f027Uo6R0lLly5dtDyeflq1dm1VNyGsW2rXduVBC+vcYV6zMWEaNky1Vi3VvLywI0k8QLaWIQ+I2zZYItID+L2qXiAix+NqOo2BJcBgVd0jIjWBp4BTcTWaAar6md9/NHAlsA8Ypaqv+fI+uNpSGvCEqo7z5VHPUVKMmZmZmp2dXeZrysiA9esPL2/UCP7wB9i/33WTjHyNVdlrr8Hu3Yefu1YtOPfcgp/5od4ypa2Xdbt//AO+++7w86anw7p1Zf7RGZNUcnPh+OPdNAKTJoUdTeIRkcWqmlnqdvFINsmgvMmmShX3t315VanilrS0Q6+R62UpW7my+ON36nSo3gGlr5dnu+ISiohLhMakoptvhr/8BXJy3B+ZprCyJhsbQaCCWrWKXrNp0QJWrIieMKpUiU3f/OJqVenpsGTJkR+/vOdVdQ+43XSTq1nZ8wcmVWzfDlOnwmWXWaI5UjY2WgWNGwe1axcuq10b7r8fGjaEevXc+5o1XTfJtLTYfQkXd+5x42Jz/PKct1Yt6NcPli2Dnj3hlFPgb3+D778PNhZj4mHyZPj2WxtwMxYs2VTQoEHuL570dJdE0tPd+0GDUvfc0c47bRo895y7xTZjhpu18KqrXM1vzBjYsiXYmIwJyu7d7vZZr17QsWPY0SQ/a7PxyttmY6JThYUL4eGH4ZVXoEYNGDzYTZvbvn3Y0RlTdo89BiNHun/PPXqEHU3iKmubjdVsTEyJwNlnu2cS/vtfuOIKN0ruKae422yvv16xjhXGxNP+/TBhAnTt6qYSMEfOko0JzIknwpQp8OWXrr1nxQro3dvVcKZNi95925hEMGcOfPop3HabdXiJFUs2JnBNmsCdd7p2nSefhOrVYcQI165z992weXPYERpziKobmqZNG+jbN+xoUoclGxM31avD5ZfDxx+7++Ddu8O997qkc+WVruZjTNjeeMP9G73lFteL1MSGJRsTdyKuwXXuXNeuc9VV8OyzbkKqc891IyTYQ6ImLOPHw7HHuj+MTOxYsjGhOuEEePRR165z331uYqo+faBdO9fN2tp1TLxkZUGzZvCvf7nnxObMCTui1GLJxiSExo3h9tvh88/h6afdw6PXXAMtW7qx5iZPttGmTXCyslw74qZN7v2OHe69/TuLHXvOxrPnbBKLKrzzDjz0ELz00uGf164dv4doTeoraQgoG2S2ZDYQZzlZsklczZvDhigzEtkXgYmV4gbWtUFmS2cPdZqUsXFj9PIvvohvHCZ11asXvbxVq/jGkcos2ZiEV9x/eFW49NJD99mNqYj//Ad27XLj+kWKx+C2lUmJyUZEzo5Yb13ks0uCCsqYSMWNcn3ppW5YnLZt3SCgdkfYlNd338HQoe6W7GOPhTOwbmVRWs1mQsR60Y6Ad8U4FmOiKm6U69mz3dQG7dq5Mdh69nS92YwpqzvucJOiTZ8Ow4e7NsADB9xrpUg0WVlx6+ZZWrKRYtajvS/8oUhNEVkkIstEZKWIjPXlM0TkcxFZ6pdOvlxEZJKI5IjIchHpHHGsoSKy1i9DI8q7iMgKv88kETeKkYg0FpEFfvsFItKoDD8Lk8AGDYr+RXDiifDvf7tndd5/3427NnGiG0jRmJK8+SY88gjccAOcdVbY0YSgoL/3+vXutsD69cH291bVYhfg42jr0d5H2VeAun69GvAh0A2YAfSLsn0f4DW/XzfgQ1/eGPjMvzby6438Z4uA7n6f14DevvwB4Ha/fjswvqRYVZUuXbqoSW5ffKF6/vluEuvTTlNdsSLsiEyi2rlTtVUr1TZtVL/7LuxoQtKsWeSs74eW9PRyHQbI1lK+X1W11JrN8SIyV0RejlgveN+6pB19HN/6t9X8UtJd9b7Ak36/D4CGItIM6AksUNWvVXU7sADo5T+rr6rv+wt+Ergo4lgz/frMiHKTwlq2dG04WVluxN7Ond0Ebnv2hB2ZSTQ33QS5uTBz5uHtgSlt0yb38Nqpp8a9m2dpyaYv8Gdc203BesH7Ur/ARSRNRJYCW3AJ40P/0Th/q+xhEanhy5oDX0bsnuvLSirPjVIOcIyqbgTwr0eXFqtJDSLw61/D6tXQvz+MHeuSzgcfhB2ZSRTz5rmpy2+91Q0Gm/Ly892kUr17u4fWbr7ZzVXfqJjWhYD6e5eYbFT135EL8B9gF7Davy+Rqu5X1U5AC6CriLQH7gBOAn6CuzV2m988WhuQVqC8zERkhIhki0h2Xl5eeXY1Ce6oo9ywN/PmwTffwE9/6mYL/fbb0vc1qevrr+Hqq13b3pgxYUcToAMHXKPUFVfAMce4Rs5Vq9yYUKtXw6JFrsEqWjfPgPp7l9b1+TERaefXGwDLcLerlojIwLKeRFV3AG8BvVR1o79VtgeYDnT1m+UCLSN2awFsKKW8RZRygM3+Nhv+dUsxcU1V1UxVzWzatGlZL8ckkT59YOVKuO46N598+/bwz3+GHZUJy29/C3l5bl6lGjVK3z7prFrluthlZMA557jRRPv3d3N6fP65SyQnneS2La6bZ1Dd8Epq0AFWRqyPAl7068cCS0rZtynQ0K/XAt4BLgCa6aEOBBOB+/378yncQWCRHuog8Dmuc0Ajv97Yf/aR37agg0AfX/4ghTsIPFBa45V1EEh977yjeuKJrg106FDVbdvCjsjE03PPud/92LFhRxJjmzerTpyo2qWLu8C0NNU+fVSfeSYuvR8oYweB0pLNkoj1ecCwaJ8Vs28HYAmwHPgE+KMvfxNY4cue5lCPNQEeBT71n2dGHOtKIMcvV0SUZ/rjfAr8lUNjvTUB3gDW+tfGpf0gLNlUDrt3q44erVq1qurRR6s++6zqgQNhR2WCtmmT6lFHue/jvXvDjiYG8vNVZ81y3S/T0txXeefOqg8/7C42jsqabEociFNEFuI6BHwFLAROUtVNIlIV+ERVTyp25yRjA3FWLsuWuYf4Fi+GCy90Uxg0b176fib5qMIll7hJ+RYvdg8BJ6UDB9xQ6E89Bc8958bYad4cBg92M72FdGFlHYizaimfXwNMwt02G6WqBaNQnYOr6RiTlDp2dD3UJk6EP/7RDXnz4INu1tAqNmJgSnn6aXjxRff7TcpEs2aNSzBPP+0evKxTB/r1cwmmR4+kmbvaphjwrGZTeX36qeuhtHAhnHkmTJsGbdqEHZWJhdxc1ymkfXs30kRCfi9nZcHo0e75llatXCN+z54wa5ZLMosWub+Azj3XJZiLLnIJJ0HEZD4bEZlU0s6qekMFYktIlmwqN1X37MXvf+8eAh071j34V3QkYJM8VN2jJe+8426b/vjHYUcURcGQMfn5h8rS0twtM1VXBb/8cvfwWLNm4cVZgljNZ3Mt8DNcl+JsYHGRxZiUIOJuoa1aBb16wW23wWmnwdKlcR2r0MTQtGkwfz488ECCJhpwNZrIRANuYL969VyGXLrUPYSZoImmPEqr2TQBLgUuA/YBzwJz1A0bk1KsZmMKqLrHE66/HrZscX9o7tt36HObkjrxffYZdOgA3bq556oSth0uBaYIjUnNRlW3qepjqnoWMAxoCKwUkctjE6YxiUfEtb+uWuUSS2SiAfeH6OjR4cRmSnfggHtwvkoVeOKJBE40UHwXyBScIrRMd6T9cP8DgXNxD0/aLTST8ho3PvwORwGbkjpxTZoEb7/tEk1Cf2cX3C4rKkWnCC1tuJqxIrIYuAn4N+5By+Gquiou0RkTsuK+rNLS3JfZ3r3xjceUbM0aN1rLBRfAsGFhR1OKMWPcOGUjRlSKKUJLa7M5gJs/ZrcvKthYcLMIdAg2vPixNhsTTbTOQtWru/ba9euhRQvXfnv11QnVG7VS2rcPfvYzWLsWPvkkwdvU5893XeWuuMJ1g0xiseqN1hr3AOcFfvmlXwrWjUlp0cYqfOIJN6bh66/Dj34EN97oakBjx7pRhU04HnwQPvzQzdqa0IkmN9c99d++vRt5uZKo0EOdIpIGDFDVlOkEajUbU1Hvvw/33ecmbqtTB665xj2jY8PfxM/y5ZCZ6Z53fPZZ94dBQvrhBzcH9bJlkJ3t5jVPcjGp2YhIfRG5Q0T+KiLnifNb3K21/rEK1phk1r07zJ3rvvAuushNZXD88e7W2tq1YUeX+vbuhSFD3FxgkycncKIB143xvffg8cdTItGUR2m30Z4CTsSNwnwV8E+gH9BXVfsGHJsxSeWUU9zwVWvXukE+n3rKTR1y2WWwZEnY0aWue+91FYVp09ykeQlr7lx3r2/kSPePopIprYPAClU9xa+nAVuBVqr6TZziixu7jWZibdMmN9Dn5MluttBevVxPqZ//PMH/+k4iH33kapaDB8OMGWFHU4J16+DUU12V9733oGbNsCOKmVh1EPihYEVV9wOfp2KiMSYIxx4L99/vnsn505/c8PZnnul6TL38cvQHx03Z7d4NQ4e6zgATJ4YdTQn27HGzZaq6qQFSKNGUR2nJpqOI7PLLN0CHgnUR2RWPAI1Jdg0buhrN+vXw17/CV1+5OXQ6dHBdq4uOUGDK5g9/cI+p/O1v7mecsG65xVXBpk93NZtKqrThatJUtb5f6qlq1Yj1+vEK0phUUKsW/OY3rk3nySfdsCqDB8MJJ8CUKfD992FHmDzeeQceegiuvRbOOy/saErw3HOue/ONN8LFF4cdTagCGzVIRGqKyCIRWSYiK0VkrC9vLSIfishaEXlWRKr78hr+fY7/PCPiWHf48jUi0jOivJcvyxGR2yPKo57DmERQrZobNX7FCjep19FHw3XXuRGlx493EzCa4n37rRsdICPDtbcnrIKeIt26ufuplVyQQ9TtAc5W1Y5AJ6CXiHQDxgMPq2obYDsw3G8/HNiuqj8GHvbbISJtgQFAO6AXMFlE0nyHhUeB3kBbYKDflhLOYUzCqFIF+vZ1z+m8+aa7rXb77e4B0dGjXW3HpjY43K23uodqZ8yAunXDjqYYu3fDpZe6vyyefdYNO1HZqWrgC1Ab+Bg4DdeY9xf1AAAXxklEQVSjraov7w7M9+vzge5+varfToA7gDsijjXf73dwX19+h1+kuHOUtHTp0kWNCVt2tmq/fqquNbnwUru26tNPhx1huP75T/ezuOmmsCMpxdVXu0DnzQs7ksAB2VqGPBDo4Nu+BrIU2AIsAD4FdqhqQZNoLlDwnHVz4EsA//lOoElkeZF9iitvUsI5jEloXbq42/zHHXf4Z/n5ruZTWe3cCVde6Z5d+r//CzuaEjz1lHvo5447oE+fsKNJGIEmG1Xdr6qdgBZAV+DkaJv512hPHmgMyw8jIiNEJFtEsvPy8qJtYkwoNm6MXp6bCz16uGd3Nm2Ka0ihGzXK/VxmznSdLRLSqlWu18IZZ8A994QdTUKJy7RCqroDeAvoBjQUkYJ5dFrgppwGVwNpCeA/bwB8HVleZJ/iyreWcI6icU1V1UxVzWzatOmRXKIxMVXc1AYNGkBenuvVdtxxbpitypB45s51bTR33AFdu4YdTTG++87Nule3LjzzDFQt03RhlUaQvdGaikhDv14L+AWwGliIG/IGYCjwkl+f69/jP3/T3w+cCwzwvdVaA22ARcBHQBvf86w6rhPBXL9PcecwJimMG+fm0IpUu7Yb0XjlSjeE/h//CJs3u8TTvPmhxLN5czgxB2XrVjfNQ8eO7tmahKTqhqH573/h73+Pfh+0sitLw05FFqADsARYDnwC/NGXH49LFjnAc0ANX17Tv8/xnx8fcazRuPaeNUDviPI+wP/8Z6MjyqOeo6TFOgiYRPP006rp6aoi7rW4zgGffKJ6992qJ5/s2qSrVFHt0UN18mTVTZviGHBA+vdXrVZNdenSsCMpwbRp7oc/dmzYkcQdZewgUKEpBlKRjY1mkp2qq/U89xzMnu3+yK5SxQ2Rc+mlcMklcMwxYUdZPs8+CwMGuJrenXeGHU0xli51z9KccQa89pqbxrUSKevYaJZsPEs2JpWkQuLZtAnatYMf/9iNXZmQTSC7drkuhPn5bmjvo48OO6K4i9VAnMaYJCTiJoIcO9Z1kFqxwj0oumGDG63guOPg7LPhscdgy5awoz0kK+vQg6zHH+++y2fOTNBEowpXXeWeMJ01q1ImmvKwZGNMiitIPPfc4wauXL78UOIZOdKNmnzOOYUTT+SXfrxGL8jKch0B1q933+O7d7vYFy8O/twV8uijrur4pz+5eSNMiew2mme30Uxlo+p6tc2e7b4z16xxyeWkkyAnx82AWaB2bZg6FQYNcgOI7t/vRqvev7/wUrSsPO8vvzx6LSs93U0Hk1A++ghOPx169oSXXnI/uErK2mzKyZKNqcxU3a22555zY0Ym0rQHIi7BJYzt291EaKqunaZx47AjClVZk00i3gk1xsSZiBsItEMH1/OrOH/4g2s/SUs7tMTq/a9+Ff3h1OIecA2FqpuxbcMGN89BJU805WHJxhhTSKtWrt2kqPT0YEdgmTDBtdnk5x8qq1275OQXd3/+s5tm9S9/gdNOCzuapFJ5bzQaY6IqbvSCoL/0Bw1y7ULp6a6mlZ5+qJ0oIbz3nhsJ9Ve/gt/+Nuxoko612XjWZmPMIVlZrsfaF1+4ms64cQn0pR+GvDzXTlOzpuse16BB2BElDGuzMcZU2KBBlTy5RDpwwHWV27rVzXRniaZCLNkYY0xJ7rsP5s+H//f/XO3GVIi12RhjTHEWLnTDaw8aBFdfHXY0Sc2SjTHGRLNpEwwcCCec4IZXkGjzMpqysttoxhhT1P79LtHs2gVvvOEmRDNHxJKNMcYUNWYMvPWWmx60XbuQg0kNlmyMMQYK9/dWdfMxDB1a+n6mTKzNxhhjig45DbBoUXyGu64kAks2ItJSRBaKyGoRWSkiv/PlY0TkKxFZ6pc+EfvcISI5IrJGRHpGlPfyZTkicntEeWsR+VBE1orIsyJS3ZfX8O9z/OcZQV2nMSYFjB5deJwccHMcjB4dTjwpKMiazT7gZlU9GegG/EZE2vrPHlbVTn55FcB/NgBoB/QCJotImoikAY8CvYG2wMCI44z3x2oDbAeG+/LhwHZV/THwsN/OGGOi++KL8pWbcgss2ajqRlX92K9/A6wGmpewS19glqruUdXPgRygq19yVPUzVd0LzAL6iogAZwPP+/1nAhdFHGumX38eOMdvb4wxhytuVICEGnI6ucWlzcbfxjoV+NAXXS8iy0XkCRFp5MuaA19G7Jbry4orbwLsUNV9RcoLHct/vtNvb4wxhT3/POzY4eY5iJRwQ04nt8CTjYjUBeYAo1R1FzAF+BHQCdgI/Llg0yi7awXKSzpW0dhGiEi2iGTn5eWVeB3GmBS0aJEb9+ynP4XHH0/gIaeTX6Bdn0WkGi7RZKnqPwBUdXPE59OAV/zbXKBlxO4tgA1+PVr5VqChiFT1tZfI7QuOlSsiVYEGwNdF41PVqcBUcKM+V/xKjTFJ54sv4MILoVkzePFFaNoUhg0LO6qUFWRvNAH+BqxW1YciyptFbHYx8IlfnwsM8D3JWgNtgEXAR0Ab3/OsOq4TwVx1cyMsBPr5/YcCL0Ucq6CDfD/gTbW5FIwxBXbtggsugO+/h1decYnGBCrIms3pwOXAChFZ6svuxPUm64S7rbUOuAZAVVeKyGxgFa4n229UdT+AiFwPzAfSgCdUdaU/3m3ALBH5P2AJLrnhX58SkRxcjWZAgNdpjEkm+/bBgAGwahW8/jq0bVv6PuaI2eRpnk2eZkwlccMN8MgjbsqAESPCjibplXXyNBtBwBhTeTzyiFtuvtkSTZxZsjHGVA6vvgqjRkHfvjDenvOON0s2xpjUt3w5XHYZdOzoxjsr+kyNCZwlG2NMatu0yfU8q18fXn4Z6tQJO6JKyaYYMMakrvx89yzNtm3w7rvQvKQRs0yQLNkYY1LTgQMwZAhkZ7uHNk89NeyIKjVLNsaY1HTXXTBnDvz5z652Y0JlbTbGmNQzfTrcdx9ccw3ceGPY0Rgs2RhjUs1bb7lnaM491z1TY7OLJARLNsaY1PG//8Ell0CbNjB7NlSrFnZExrNkY4xJDdu2wfnnQ9WqMG8eNGwYdkQmgnUQMMYkvz17XI3myy/hzTehdeuwIzJFWLIxxiQ3VdcR4O234e9/dxOhmYRjt9GMMcntvvtg5kwYOxYGDgw7GlMMSzbGmOQ1ezaMHg2DB8Mf/hB2NKYElmyMMcnpww9h6FD42c/g8ceti3OCC3Ja6JYislBEVovIShH5nS9vLCILRGStf23ky0VEJolIjogsF5HOEcca6rdfKyJDI8q7iMgKv88kPxV1secwxqSIdevcqADHHQcvvAA1aoQdkSlFkDWbfcDNqnoy0A34jYi0BW4H3lDVNsAb/j1Ab6CNX0YAU8AlDuBu4DSgK3B3RPKY4rct2K+XLy/uHMaYZLdzpxvFec8e18X5qKPCjsiUQWDJRlU3qurHfv0bYDXQHOgLzPSbzQQu8ut9gSfV+QBoKCLNgJ7AAlX9WlW3AwuAXv6z+qr6vrq5rZ8scqxo5zDGJLN9+9y8NGvWuHHPTjop7IhMGcWl67OIZACnAh8Cx6jqRnAJSUSO9ps1B76M2C3Xl5VUnhulnBLOYYxJVqrwu9/B/PkwbRqcc07YEZlyCLyDgIjUBeYAo1R1V0mbRinTCpSXJ7YRIpItItl5eXnl2dUYE2+PPAKTJ8Mtt8BVV4UdjSmnQJONiFTDJZosVf2HL97sb4HhX7f48lygZcTuLYANpZS3iFJe0jkKUdWpqpqpqplNmzat2EUaY4I3b54bvfmii+D++8OOxlRAkL3RBPgbsFpVH4r4aC5Q0KNsKPBSRPkQ3yutG7DT3wqbD5wnIo18x4DzgPn+s29EpJs/15Aix4p2DmNMslm2DAYMcJOfPf00VLEnNpJRkG02pwOXAytEZKkvuxO4H5gtIsOBL4BL/WevAn2AHCAfuAJAVb8WkXuBj/x296jq1359JDADqAW85hdKOIcxJpls3Oh6njVsCHPnQp06YUdkKkhcRy6TmZmp2dnZYYdhjCmQnw9nngmrV8O770KnTmFHZKIQkcWqmlnadlYfNcYkjqwsyMhwt8qOOgqys2HWLEs0KcBGfTbGJIasLDfDZn6+e797t5v8bOfOcOMyMWE1G2NMYhg9+lCiKfDDD67cJD2r2RhjwrVrFzzzDKxfH/3zL76IbzwmEJZsjDHxpwr/+Y8brXn2bFejqVbN1WSKatUq/vGZmLPbaMaY+MnLgz//Gdq2dVMDPP+8m4tm0SKYPh1q1y68fe3aMG5cOLGamLKajTEmWAcOwL/+5cYze+klV3vp3h3+9jfo3x/q1nXb/eQn7nX0aHfrrFUrl2gGDQovdhMzlmyMMcH48ktXW3niCdce06QJXH89DB8O7dpF32fQIEsuKcqSjTEmdn74AV5+2bXFvP66a5s591x44AHo29cmOavELNkYY47cmjXuttjMmbBlCzRvDnfdBVdcAa1bhx2dSQCWbIwxFZOf7xr4H38c3nkHqlaFX/7SDf/fsyekpYUdoUkglmyMMeWzZIlLMFlZ7un+Nm1g/HgYMgSOPTbs6EyCsmRjjDlcVlbhXmF33eXaYx5/HD7+GGrWhH794Oqr4ec/B4k2l6Exh1iyMcYUVnSMsvXrXVIB6NgR/vpX+PWvoVGj8GI0SceSjTGV2Q8/QG4urFvnlvXrYcKEw8coA3eLbMkSq8WYCrFkY0wq27PHPe9SkEgik8q6dfDVV+6hywIirrtyNJs3W6IxFWbJxphEVbTdJNrT9N9/7z4vmkQK1jdsKJw8qlSBFi3cnDFnnQXp6W69YGnRAk44IfqgmDZGmTkCgSUbEXkCuADYoqrtfdkY4Gogz292p6q+6j+7AxgO7AduUNX5vrwX8BcgDXhcVe/35a2BWUBj4GPgclXdKyI1gCeBLsA24DJVXRfUdZpKoCxf+kGcs2i7yZVXuonE6tY9lFA2bSq8X1qaizE93T1MmZFROKE0b+4GvCzJuHGFzw02Rpk5YoFNCy0iZwDfAk8WSTbfquqEItu2BZ4BugLHAf8CTvAf/w84F8gFPgIGquoqEZkN/ENVZ4nIY8AyVZ0iItcBHVT1WhEZAFysqpeVFq9NC22iKvqlD+6Ld+rU6AlH1d262rXLLTt3Hlovz/tt24qP6Uc/OjyJFKwfd5x73iUW121jlJkyKOu00IElGx9EBvBKGZLNHQCqep9/Px8Y4z8eo6o9I7cD7sfVjo5V1X0i0r1gu4J9VfV9EakKbAKaaikXaskmwcXjy0/V3ZbasQO2b3evF13kRiouqnZtOPvs6Iki2jD5RVWrBg0auKV+/cJLgwYweXL0/UQKt7EYE7KyJpsw2myuF5EhQDZws6puB5oDH0Rsk+vLAL4sUn4a0ATYoar7omzfvGAfn4h2+u23xvxKwvzrL6xzJ8otpREj3HrRc//wg0sSkQmjLO8L1vfuLVtM+fmucb1+fWjZsvikUdz70sYImzfP2k1MSol3spkC3Auof/0zcCUQrYuLEn2+HS1he0r5rBARGQGMAGhV3v/E5fkCjLWwzl3e86q6L/+9ew8te/YUfl+WsmjTBefnu2c/pkwpnEC++67ka6hWzT0f0rDhoSUjo/D7yM+HDTu8XQTcbauPPy7vT7DsrN3EpJi4JhtV3VywLiLTgFf821ygZcSmLYANfj1a+VagoYhU9bWbyO0LjpXrb6M1AL4uJp6pwFRwt9HKdTHFfQFedx0sXRrtZGU/dmnbTpsW/dzXXgvvvedus0QuqoeXFVdeUtl//uOSQNHzDhvmfh7RkkaQdu92NYQTTyycIIomk8j3tWqVr/vuhAnhfOkXJG9rNzEpIq7JRkSaqepG//Zi4BO/Phf4u4g8hOsg0AZYhKultPE9z74CBgC/VlUVkYVAP1yPtKHASxHHGgq87z9/s7T2mgopbl70XbtKvt9eViVt++23xZc//7zr3lqwiBR+X1J5aWVFE02BffugRw+oXt19+Vevfmgp7X1ZtsnMdA8eFpWeDm+8UfafaUWE+aVvc7uYVKKqgSy43mUbgR9wtY3hwFPACmA5Lik0i9h+NPApsAboHVHeB9cj7VNgdET58biElAM8B9Tw5TX9+xz/+fFlibdLly5aLunpqu5v/sJLenr5jlMRYZ07rPM+/bRq7dqFz1m7tis3xoQKyNay5ISybFQZlnInmzC/AMM6d9jXnJ6uKuJeLdEYkxDKmmyiNcCbshg0yD1rkZ7ubjWlpxf/7EWqnDvsa163zrUdrVtnt5eMSTKBPmeTTOw5G2OMKb+yPmdjNRtjjDGBs2RjjDEmcJZsjDHGBM6SjTHGmMBZsjHGGBM4643miUgeEGXkw4R3FEEMMpq4Ktv1gl1zZZGs15yuqk1L28iSTZITkeyydDtMFZXtesGuubJI9Wu222jGGGMCZ8nGGGNM4CzZJL+pYQcQZ5XtesGuubJI6Wu2NhtjjDGBs5qNMcaYwFmyMcYYEzhLNsYYYwJnySaFiUgdEVksIheEHUs8iMhFIjJNRF4SkfPCjico/vc6019rpZjYp7L8botKpf/DlmwSkIg8ISJbROSTIuW9RGSNiOSIyO1lONRtwOxgooytWFyzqr6oqlcDw4DLAgw35sp5/ZcAz/trvTDuwcZIea45mX+3kSrw7zxp/g+XxpJNYpoB9IosEJE04FGgN9AWGCgibUXkFBF5pchytIj8AlgFbI538BU0gyO85ohd7/L7JZMZlPH6gRbAl36z/XGMMdZmUPZrLpCMv9tIMyj7v/Nk+z9coqphB2AOp6pvi0hGkeKuQI6qfgYgIrOAvqp6H3BYFVtEzgLq4P7x7haRV1X1QKCBH4EYXbMA9wOvqerHwUYcW+W5fiAXl3CWksR/MJbnmkVkNUn6u41Uzt9zXZLo/3BpLNkkj+Yc+msW3BfOacVtrKqjAURkGLA1Sf+Rluuagd8CvwAaiMiPVfWxIIOLg+KufxLwVxE5H3g5jMACVNw1p9rvNlLUa1bV6yHp/w8fZMkmeUiUslKfyFXVGbEPJW7Kdc2qOgn3RZwqol6/qn4HXBHvYOKkuGtOtd9tpBL/nSf5/+GDkrYKXgnlAi0j3rcANoQUS7xUxmuOVBmv3645Ra/Zkk3y+AhoIyKtRaQ6MACYG3JMQauM1xypMl6/XXOKXrMlmwQkIs8A7wMnikiuiAxX1X3A9cB8YDUwW1VXhhlnLFXGa45UGa/frrlyXHMBG4jTGGNM4KxmY4wxJnCWbIwxxgTOko0xxpjAWbIxxhgTOEs2xhhjAmfJxhhjTOAs2RhjjAmcJRtjjoCIfOtfO4nI+yKyUkSWi0joc66IyDoROUpEGorIdWHHYyo3SzbGxEY+MERV2+HmK5koIg1DjqlAQ8CSjQmVJRtjYkBV/6eqa/36BmAL0LS47X2tY7yILPLLj315UxGZIyIf+eV0Xz7Gz/L4loh8JiI3RBzrRXFTB68UkRFRTnc/8CMRWSoiD4rIUyLSN2L/LBFJ2hk/TXKwKQaMiTER6QpUBz4tZdNdqtpVRIYAE3ETwv0FeFhV3xWRVrjxsk72258EnAXUA9aIyBRV/QG4UlW/FpFawEciMkdVt0Wc53agvap28vGdCdwIvCQiDYCfAkNjcOnGFMuSjTExJCLNgKeAoWWY7OqZiNeH/fovgLZu0lEA6otIPb8+T1X3AHtEZAtwDG54+htE5GK/TUugDRCZbApR1X+LyKN+Ku1LgDl+MEhjAmPJxpgYEZH6wDzgLlX9oAy7aJT1KkB3Vd1d5NgAeyKK9gNVRaQHLkF1V9V8EXkLqFmGcz8FDMINZ39lGbY35ohYm40xMeDnIXkBeFJVnyvjbpdFvL7v1/+JG26+4LidSjlGA2C7TzQnAd2ibPMN7tZbpBnAKIBUHM7eJB5LNsbERn/gDGCYb4hfWoZEUUNEPgR+h2tDAbgByPTdp1cB15ZyjNdxNZzlwL3AYTUq337znoh8IiIP+rLNuLlTppfx+ow5IjafjTEhEJF1QKaqbg3p/LWBFUBnVd0ZRgymcrGajTGVjIj8Avgv8IglGhMvVrMxJkAi8gLQukjxbao6P4x4jAmLJRtjjDGBs9toxhhjAmfJxhhjTOAs2RhjjAmcJRtjjDGBs2RjjDEmcP8fQwPst4uyEK4AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the validation RMSE as a blue line with dots\n",
    "plt.plot(ridge_data['l2_penalty'], ridge_data['validation_rmse'], \n",
    "         'b-o', label='Validation')\n",
    "# Plot the train RMSE as a red line dots\n",
    "plt.plot(ridge_data['l2_penalty'], ridge_data['train_rmse'], \n",
    "         'r-o', label='Train')\n",
    "\n",
    "# Make the x-axis log scale for readability\n",
    "plt.xscale('log')\n",
    "\n",
    "# Label the axes and make a legend\n",
    "plt.xlabel('l2_penalty')\n",
    "plt.ylabel('RMSE')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we want to actually look at which model we think will perform best. First we define a helper function that will be used to inspect the model parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_coefficients(model, features):\n",
    "    \"\"\"\n",
    "    This function takes in a model column and a features column. \n",
    "    And prints the coefficient along with its feature name.\n",
    "    \"\"\"\n",
    "    feats = list(zip(model.coef_, features))\n",
    "    print(*feats, sep = \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the cell below, write code that uses the `ridge_data` `DataFrame` to select which L2 penalty we would choose based on the evaluations we did in the previous section. You should print out the following values to help you answer the next questions! \n",
    "* The best L2 penalty based on the model evaluations\n",
    "* Take the best model and evaluate its error on the **test** dataset. Report the number as an RMSE.\n",
    "* Call the `print_coefficients` function passing in the model itself and the features used so you can look at all of its coefficient values.\n",
    "\n",
    "To do this in `pandas`, you'll need to use the `idxmin()` function to find the index of the smallest value in a column and the `loc` property to access that index. As an example, suppose we had a `DataFrame` named `df`:\n",
    "\n",
    "| a | b | c |\n",
    "|---|---|---|\n",
    "| 1 | 2 | 3 |\n",
    "| 2 | 1 | 3 |\n",
    "| 3 | 2 | 1 |\n",
    "\n",
    "If we wrote the code \n",
    "```python\n",
    "index = df['b'].idxmin()\n",
    "row = df.loc[index]\n",
    "```\n",
    "\n",
    "It would first find the index of the smallest value in the `b` column and then uses the `.loc` property of the `DataFrame` to access that particular row. It will return a `Series` object (basically a Python dictionary) which means you can use syntax like `row['a']` to access a particular column of that row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "l2_penalty                                                        10\n",
      "model              Ridge(alpha=10.0, copy_X=True, fit_intercept=T...\n",
      "train_rmse                                                    162399\n",
      "validation_rmse                                               280715\n",
      "Name: 6, dtype: object\n",
      "(-13139.220846887512, 'bedrooms')\n",
      "(-5690.377838792361, 'bedrooms_square')\n",
      "(-20624.058202285352, 'bedrooms_sqrt')\n",
      "(1560.3326638434278, 'bathrooms')\n",
      "(141534.09936487765, 'bathrooms_square')\n",
      "(-49670.26698776374, 'bathrooms_sqrt')\n",
      "(23495.774981928742, 'sqft_living')\n",
      "(22090.32505856895, 'sqft_living_square')\n",
      "(13973.112171612243, 'sqft_living_sqrt')\n",
      "(16234.004592795096, 'sqft_lot')\n",
      "(19950.781311134477, 'sqft_lot_square')\n",
      "(-24986.828848425914, 'sqft_lot_sqrt')\n",
      "(-15597.323266122077, 'floors')\n",
      "(13875.60949758698, 'floors_square')\n",
      "(-26808.025961840078, 'floors_sqrt')\n",
      "(61034.99612538429, 'waterfront')\n",
      "(61034.996125384234, 'waterfront_square')\n",
      "(61034.99612538421, 'waterfront_sqrt')\n",
      "(-7673.072077662959, 'view')\n",
      "(14805.627618587247, 'view_square')\n",
      "(-15029.681204442377, 'view_sqrt')\n",
      "(4109.928064755624, 'condition')\n",
      "(4427.383100280982, 'condition_square')\n",
      "(3946.601111825622, 'condition_sqrt')\n",
      "(46883.60934503321, 'grade')\n",
      "(75746.94577130656, 'grade_square')\n",
      "(33004.6936781076, 'grade_sqrt')\n",
      "(23808.75230227078, 'sqft_above')\n",
      "(43431.94702932952, 'sqft_above_square')\n",
      "(2488.500157564076, 'sqft_above_sqrt')\n",
      "(1205.4524891616104, 'sqft_basement')\n",
      "(-34830.82265328077, 'sqft_basement_square')\n",
      "(25501.65133879781, 'sqft_basement_sqrt')\n",
      "(-27087.593521961386, 'yr_built')\n",
      "(-26707.01384308778, 'yr_built_square')\n",
      "(-27273.36763807536, 'yr_built_sqrt')\n",
      "(4923.476423145943, 'yr_renovated')\n",
      "(5318.185091748367, 'yr_renovated_square')\n",
      "(4717.156840543916, 'yr_renovated_sqrt')\n",
      "Based on this, we should use an l2 penalty of 10.\n",
      "350668.1832412408\n",
      "None of the features have a coefficient of 0 with this model.\n"
     ]
    }
   ],
   "source": [
    "# TODO Print information about best L2 model\n",
    "#Need to pick the one with the smallest RSS on the validation set.\n",
    "index = ridge_data['validation_rmse'].idxmin()\n",
    "row = ridge_data.loc[index]\n",
    "print(row)\n",
    "print_coefficients(row['model'], all_features)\n",
    "print('Based on this, we should use an l2 penalty of 10.')\n",
    "#Take the best model and evaluate its error on the test dataset:\n",
    "testError = math.sqrt(mean_squared_error(test['price'], row['model'].predict(test[all_features])))\n",
    "print(testError)\n",
    "#Number of features that have coefficient of 0?\n",
    "print('None of the features have a coefficient of 0 with this model.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q2) Based on your evaluations, which L2 penalty would you use?\n",
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Gradescope:</b> Enter one of these options on Gradescope.\n",
    "<ul>\n",
    "    <li>10<sup>-5</sup></li>\n",
    "    <li>10<sup>-4</sup></li>\n",
    "    <li>10<sup>-3</sup></li>\n",
    "    <li>10<sup>-2</sup></li>\n",
    "    <li>10<sup>-1</sup></li>\n",
    "    <li>10<sup>0</sup></li>\n",
    "    <li>10<sup>1</sup></li>\n",
    "    <li>10<sup>2</sup></li>\n",
    "    <li>10<sup>3</sup></li>\n",
    "    <li>10<sup>4</sup></li>\n",
    "    <li>10<sup>5</sup></li>\n",
    "</ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q3) For the model you chose for the Q2, what is its test RMSE?\n",
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Gradescope:</b> Type in the test error for the best <code>Ridge</code> model. You should round the RMSE to the nearest integer. \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q4) For the model you chose in Q2, what is the number of features that have coefficient 0?\n",
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Gradescope:</b> Type in the answer as an integer. \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- \n",
    "## LASSO Regression\n",
    "In this section you will do basically the exact same analysis you did with Ridge Regression, but using LASSO Regression instead. Remember that for LASSO we choose the parameters that minimize this quality metric instead \n",
    "\n",
    "$$\\hat{w}_{LASSO} = \\min_w RSS(w) + \\lambda \\left\\lVert w \\right\\rVert_1$$\n",
    "\n",
    "where $\\left\\lVert w \\right\\rVert_1 = \\sum_{j=0}^D \\lVert w_j \\rVert$ is the L1 norm of the parameter vector.\n",
    "\n",
    "We will use the same set of instructions for LASSO as we did for Ridge, except for the following differences. Please refer back to the Ridge Regression instructions and your code to see how these differences fit in!\n",
    "\n",
    "* Use the [Lasso](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Lasso.html#sklearn.linear_model.Lasso) model. Like before, the only parameters you need to pass in are `alpha` for the L1 penalty and `random_state=0`.\n",
    "* The range L1 penalties should be $[10, 10^2, ..., 10^7]$. In Python, this is `np.logspace(1, 7, num=7)`.\n",
    "* The result should be stored in a `DataFrame` named `lasso_data`. All the columns should have the same name and corresponding values except the penalty column should be called `l1_penalty`.\n",
    "* It is okay if your code prints some `ConvergenceWarning` warnings, these should not impact your results!.\n",
    "\n",
    "You do not need to worry about your code being redundant for this part."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   l1_penalty                                              model  \\\n",
      "0        10.0  Lasso(alpha=10.0, copy_X=True, fit_intercept=T...   \n",
      "1       100.0  Lasso(alpha=100.0, copy_X=True, fit_intercept=...   \n",
      "2      1000.0  Lasso(alpha=1000.0, copy_X=True, fit_intercept...   \n",
      "3     10000.0  Lasso(alpha=10000.0, copy_X=True, fit_intercep...   \n",
      "4    100000.0  Lasso(alpha=100000.0, copy_X=True, fit_interce...   \n",
      "5   1000000.0  Lasso(alpha=1000000.0, copy_X=True, fit_interc...   \n",
      "6  10000000.0  Lasso(alpha=10000000.0, copy_X=True, fit_inter...   \n",
      "\n",
      "      train_rmse  validation_rmse  \n",
      "0  151342.180884    335241.388585  \n",
      "1  152194.025911    322816.843560  \n",
      "2  156518.588018    284368.235272  \n",
      "3  170238.979692    268444.047540  \n",
      "4  262480.902123    414751.280563  \n",
      "5  357105.698956    533861.713077  \n",
      "6  357105.698956    533861.713077  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Tellurium-Winpython-3.6\\python-3.6.6.amd64\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "# TODO Implement code to evaluate LASSO Regression with various L1 penalties\n",
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "L2penalties = np.logspace(1,7,num = 7)\n",
    "#Only need to use alpha and random_state = 0\n",
    "lasso_data = []\n",
    "for penalty in L2penalties:\n",
    "    LassoRegression = Lasso(alpha = penalty, random_state = 0)\n",
    "    LassoRegression.fit(X,Y)\n",
    "    #Find the training and validation error:\n",
    "    LassoTrainError = math.sqrt(mean_squared_error(train['price'], LassoRegression.predict(train[all_features])))\n",
    "    LassoValidationError = math.sqrt(mean_squared_error(validation['price'], LassoRegression.predict(validation[all_features])))\n",
    "    lasso_data.append({'l1_penalty': penalty, 'model': LassoRegression, 'train_rmse': LassoTrainError,\n",
    "      'validation_rmse': LassoValidationError})\n",
    "\n",
    "lasso_data = pd.DataFrame(lasso_data)  \n",
    "print(lasso_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is a sanity check like before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert type(lasso_data) == pd.DataFrame\n",
    "assert len(lasso_data) == 7\n",
    "\n",
    "for col in ['l1_penalty', 'model', 'train_rmse', 'validation_rmse']:\n",
    "    assert col in lasso_data.columns, f'Missing column {col}'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like before, let's look at how the L1 penalty affects the performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1d474f10908>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the validation RMSE as a blue line with dots\n",
    "\n",
    "plt.plot(lasso_data['l1_penalty'], lasso_data['validation_rmse'],\n",
    "         'b-o', label='Validation')\n",
    "\n",
    "# Plot the train RMSE as a red line dots\n",
    "plt.plot(lasso_data['l1_penalty'], lasso_data['train_rmse'],\n",
    "         'r-o', label='Train')\n",
    "\n",
    "# Make the x-axis log scale for readability\n",
    "plt.xscale('log')\n",
    "\n",
    "# Label the axes and make a legend\n",
    "plt.xlabel('l1_penalty')\n",
    "plt.ylabel('RMSE')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like before, in the cell below, write code that uses the `lasso_data` `DataFrame` to select which L1 penalty we would choose based on the evaluations we did in the previous section. You should print out the following values to help you answer the next questions! \n",
    "* The best L1 penalty based on the model evaluations\n",
    "* Take the best model and evaluate it on the test dataset and report its RMSE\n",
    "* Call the `print_coefficients` function passing in the model itself and the features used so you can look at all of its coefficient values. Note some of the values are `-0.0` which is the same as `0.0` for our purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "l1_penalty                                                     10000\n",
      "model              Lasso(alpha=10000.0, copy_X=True, fit_intercep...\n",
      "train_rmse                                                    170239\n",
      "validation_rmse                                               268444\n",
      "Name: 3, dtype: object\n",
      "(-0.0, 'bedrooms')\n",
      "(-0.0, 'bedrooms_square')\n",
      "(-19129.613383175547, 'bedrooms_sqrt')\n",
      "(-0.0, 'bathrooms')\n",
      "(113626.05363381634, 'bathrooms_square')\n",
      "(-0.0, 'bathrooms_sqrt')\n",
      "(0.0, 'sqft_living')\n",
      "(0.0, 'sqft_living_square')\n",
      "(0.0, 'sqft_living_sqrt')\n",
      "(0.0, 'sqft_lot')\n",
      "(8103.923178885518, 'sqft_lot_square')\n",
      "(0.0, 'sqft_lot_sqrt')\n",
      "(-0.0, 'floors')\n",
      "(-0.0, 'floors_square')\n",
      "(-12044.473362529397, 'floors_sqrt')\n",
      "(172128.40168391765, 'waterfront')\n",
      "(4.97322548160468e-09, 'waterfront_square')\n",
      "(1.2900714608572452e-11, 'waterfront_sqrt')\n",
      "(0.0, 'view')\n",
      "(0.0, 'view_square')\n",
      "(-0.0, 'view_sqrt')\n",
      "(0.0, 'condition')\n",
      "(0.0, 'condition_square')\n",
      "(0.0, 'condition_sqrt')\n",
      "(0.0, 'grade')\n",
      "(155737.85002833256, 'grade_square')\n",
      "(0.0, 'grade_sqrt')\n",
      "(0.0, 'sqft_above')\n",
      "(73015.38607305191, 'sqft_above_square')\n",
      "(0.0, 'sqft_above_sqrt')\n",
      "(0.0, 'sqft_basement')\n",
      "(-0.0, 'sqft_basement_square')\n",
      "(0.0, 'sqft_basement_sqrt')\n",
      "(-82585.79757661703, 'yr_built')\n",
      "(-0.0, 'yr_built_square')\n",
      "(-742.340910826097, 'yr_built_sqrt')\n",
      "(0.0, 'yr_renovated')\n",
      "(0.0, 'yr_renovated_square')\n",
      "(0.0, 'yr_renovated_sqrt')\n",
      "Based on this, we should use an l2 penalty of 10000.\n",
      "341484.0599829632\n",
      "28 of the features have a coefficient of 0 with this model.\n",
      "39\n"
     ]
    }
   ],
   "source": [
    "# TODO Print information about best L1 model\n",
    "index = lasso_data['validation_rmse'].idxmin()\n",
    "row = lasso_data.loc[index]\n",
    "print(row)\n",
    "print_coefficients(row['model'], all_features)\n",
    "print('Based on this, we should use an l2 penalty of 10000.')\n",
    "#Take the best model and evaluate its error on the test dataset:\n",
    "testError = math.sqrt(mean_squared_error(test['price'], row['model'].predict(test[all_features])))\n",
    "print(testError)\n",
    "#Number of features that have coefficient of 0?\n",
    "print('28 of the features have a coefficient of 0 with this model.')\n",
    "print(len(all_features))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q5) Based on your evaluations, which L1 penalty would you use?\n",
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Gradescope:</b> Enter one of these options on Gradescope.\n",
    "<ul>\n",
    "    <li>10<sup>1</sup></li>\n",
    "    <li>10<sup>2</sup></li>\n",
    "    <li>10<sup>3</sup></li>\n",
    "    <li>10<sup>4</sup></li>\n",
    "    <li>10<sup>5</sup></li>\n",
    "    <li>10<sup>6</sup></li>\n",
    "    <li>10<sup>7</sup></li>\n",
    "</ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q6) For the model you chose for Q5, what is its test RMSE?\n",
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Gradescope:</b> Type in the test error for the best <code>Lasso</code> model. You should round the RMSE to the nearest integer. \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q7) For model you chose for Q5, which of the features did it choose to keep (i.e. do NOT have coefficient 0)?\n",
    "<div class=\"alert alert-block alert-success\" style=\"overflow: auto\">\n",
    "    <p><b>Gradescope:</b> Enter all of these options that apply on Gradescope.</p>\n",
    "    \n",
    "<div style=\"width: 50%; float: left;\">\n",
    "<ul>\n",
    "    <li>bedrooms</li>\n",
    "    <li>bedrooms_square</li>\n",
    "    <li>bedrooms_sqrt</li>\n",
    "    <li>bathrooms</li>\n",
    "    <li>bathrooms_square</li>\n",
    "    <li>bathrooms_sqrt</li>\n",
    "    <li>sqft_living</li>\n",
    "    <li>sqft_living_square</li>\n",
    "    <li>sqft_living_sqrt</li>\n",
    "    <li>sqft_lot</li>\n",
    "    <li>sqft_lot_square</li>\n",
    "    <li>sqft_lot_sqrt</li>\n",
    "    <li>floors</li>\n",
    "    <li>floors_square</li>\n",
    "    <li>floors_sqrt</li>\n",
    "    <li>waterfront</li>\n",
    "    <li>waterfront_square</li>\n",
    "    <li>waterfront_sqrt</li>\n",
    "    <li>view</li>\n",
    "    <li>view_square</li>\n",
    "    <li>view_sqrt</li>\n",
    "</ul>\n",
    "</div>\n",
    "<div style=\"width: 50%; float: right;\">\n",
    "<ul>\n",
    "    <li>condition</li>\n",
    "    <li>condition_square</li>\n",
    "    <li>condition_sqrt</li>\n",
    "    <li>grade</li>\n",
    "    <li>grade_square</li>\n",
    "    <li>grade_sqrt</li>\n",
    "    <li>sqft_above</li>\n",
    "    <li>sqft_above_square</li>\n",
    "    <li>sqft_above_sqrt</li>\n",
    "    <li>sqft_basement</li>\n",
    "    <li>sqft_basement_square</li>\n",
    "    <li>sqft_basement_sqrt</li>\n",
    "    <li>yr_built</li>\n",
    "    <li>yr_built_square</li>\n",
    "    <li>yr_built_sqrt</li>\n",
    "    <li>yr_renovated</li>\n",
    "    <li>yr_renovated_square</li>\n",
    "    <li>yr_renovated_sqrt</li>\n",
    "</ul>\n",
    "</div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q8) Based on our experiments, which model would we expect to perform best in the future?\n",
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Gradescope:</b> Select the option on that best applies on Gradescope.\n",
    "<ul>\n",
    "    <li>LinearRegression</li>\n",
    "    <li>Ridge</li>\n",
    "    <li>Lasso</li>\n",
    "    <li>We are unable to tell that without having future data.</li>\n",
    "</ul>\n",
    "</div>\n",
    "\n",
    "Once you are done, head over to Gradescope to submit this assignment and do the concept portion!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## [Optional Challenge] Grid Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section is not worth any points and you do not need to complete it. It is here if you have extra time and want to look at something a bit more advanced that you could use in practice.\n",
    "\n",
    "As we discused in lecture, there are pros to using Ridge and pros to using LASSO. ElasticNet is a model that allows you to use both and tune how much importance you put to one vs the other. The quality metric for ElasticNet is: \n",
    "\n",
    "$$\\hat{w}_{ElasticNet} = \\min_w RSS(w) + \\lambda_1 \\left\\lVert w \\right\\rVert_1 + \\lambda_2 \\left\\lVert w \\right\\rVert_2^2$$\n",
    "\n",
    "However, the `sklearn` implementation asks you to specify the paramters slightly differently. Instead of specifying a $\\lambda_1$ and $\\lambda_2$, they ask you to speciy `alpha` ($\\alpha$) and `l1_ratio` ($\\rho$).\n",
    "\n",
    "$$\\hat{w}_{ElasticNet} = \\min_w RSS(w) + \\alpha*\\rho \\left\\lVert w \\right\\rVert_1 + \\alpha*(1-\\rho) \\left\\lVert w \\right\\rVert_2^2$$\n",
    "\n",
    "Where $\\alpha$ is the penalty strength and $\\rho$ is the ratio of the penalty that goes to the L1 penalty vs the L2 penalty. $\\rho$ should be a number between 0 and 1.\n",
    "\n",
    "Grid Search is a process of tuning multiple hyper-parameters at the same time by using cross validation. It is essentially the same as what you did in the code above, but uses nested loops to try all possible pairs of settings.\n",
    "\n",
    "For this exercise, look at the documentation for [ElasticNet](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Lasso.html#sklearn.linear_model.ElasticNet) and [GridSearchCV](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html#sklearn.model_selection.GridSearchCV) to find the optimal settings of the hyper-parameters `alpha` and `l1_ratio`. \n",
    "\n",
    "\n",
    "*Some implemenation details*\n",
    "* Use $k$-fold cross validation with $k=4$.\n",
    "* Use $\\alpha$ with values `np.logspace(2,5,4)` and $\\rho$ (`l1_ratio`) with values `np.linspace(0,1,5)`.\n",
    "* At the end, print the best set of paramters found by grid search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
